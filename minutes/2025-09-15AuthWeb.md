# Authentic Web mini-workshop series: Originator Profile

Sep 15, 2025

[Reading Materials and Slides](https://github.com/w3c/authentic-web-workshop/issues/28)
[Video Record](https://customer-0kix77mxh2zzzae0.cloudflarestream.com/8e8d8c54403b54a7966057a6fc977798/watch)

Chat: irc.w3.org #CredWeb
Chair: [Tzviya Siegman](mailto:tzviya@w3.org)
Scribe: Chris Needham

Chair: Tzviya Siegman
Present:
- Tzviya Siegman (W3C)
- Shigeya Suzuki, Keio University, Originator Profile CIP
- Dominique Hazael-Massieux (W3C)
- [Ted Thibodeau Jr](https://github.com/TallTed/) (he/him) ([OpenLink Software](https://openlinksw.com/))
- Barrett Golding, Iffy.news
- John Fisher (unaffiliated)
- James Gallagher (independent)
- Kazuhiro Hoya （OP）
- Tomoya ASAI (WebDINO)
- Virginia Balseiro ( <https://dokie.li> )
- Scott Yates, trust.txt
- Chris Needham (BBC)
- Michiko Kuriuyama (OP)
- Felipe Riberio
- Annette Greiner
- Frank Michel
- Michale Golebiewski (Microsoft Bing)
- Yosuke Ito (OP-CIP)
- Youkari Imai
- Yumi Dobashi (OP-CIP)
- Ehsan Toreini (Samsung)
- David Karger

Shigeya: I’ll introduce the OP (Originator Profile) framework, in development for the last 3 years. There is documentation available.

OP enables the user to identify the originator, or publisher, of content on the internet, and certify whether the content is correct or not.

We provide information about the originator as a set of validated attributes. The OP will sign the contents to send to the recipients. By using the scheme, relying on digital signing technology, the recipient can receive information about the originator that can help understand what kind of originator it is, and help the recipient decide about the contents.

We’re targeting web-based media such as newspapers and TV stations. Lots of misinformation is circulating, also in medical professions. We want to apply it to local government and digital advertising too.

It’s designed around a concept of signed data with policy. There’s a clear intention when the originator signs the content for the recipient. Sign the content according to the policy, and know the policy the originator is committed too, you can provide policy to the recipient, This is a key concept.

Combine the OP with third party claims under a policy. Comes from multiple issuers, which can have multiple policies. The recipient refers to the OP and verified attributes.

The OP is created by multiple issuers. One is the core profile issuer, where you verify the originator has certain keys bound to them. Validated attributes are bound to the originator. By separating these two, and providing multiple profile annotations, it can …

Content attestation includes reference to the OP. An OP can embed a content integrity descriptor alongside the content attestation, which can be used for text fragments or media references. The recipient receives the target content with the content attestations, and can refer to the OP to see the attributes of the OP that the recipient can rely on.

Deliver the content as a web page. OP has a signing key. Content attestation is included in the webpage. It can include the OP itself or refer to an external originator profile. The recipient can use the verifying key. It can check the provenance, then the …. Can be bound.

Governance, in the current X.509 model there’s a trust list with multiple CAs. It’s bound to multiple policies. For the OP, the initial bootstrap phase, the OPCIP issues core profile and organization profile and ? profile that’s specific to the media.

Media association membership information can be included. Membership-based organizations have a policy that decides whether or not an organization can be a member. The membership shows a certain policy that might be bound to requirements for how to behave in a specific ecosystem. Some media organizations need to behave in certain ways to belong. That’s key information to be used in the OP.

In the next step, if we have other countries or jurisdictions joining the scheme, there have to be jurisdiction-specific issuers. This scheme also relies on OPCIP central governance, with PAs specific to the jurisdiction. Eventually we want multiple OPCIP organizations to be issuing CPs.

We’re going to bootstrap in this way to provide a better decentralized governance model. Don’t want to control the entire governance structure. We will take a long time to establish this.

We have a new idea, can be implemented as part of the browser. Works like an EV certificate. Have specific attributes appear as part of the visualisation. We’re researching this with other stakeholders. Well present UI ideas in the future, and provide additional info.

Developed in 2023 and 24 with support from the Japanese government. We will deploy to some organizations to use OP in the near future.

Development of software in OPCIP, we need help from standards bodies like W3C, e.g., on the key rotation scheme. We have enough code developed to experiment in certain contexts.

We’re missing some functionality like key rotation, which we need to fix.

We’ll be feature-complete for static websites this year.

In phase 3 we want to implement it for local governments.

Media organizations operate differently, e.g., between small and large organizations. We have over 3000 local government organizations, most very small. There are multiple possibilities for how to deploy. 

We have a Wordpress plugin, that keeps its keys in the cloud, and embeds the content attestation in the webpage.

We have two system integrators developing cloud services. They have extended the OPCIP developed code. We want to see the diversity of the system, and to support smaller organizations.

Difference to C2PA? C2PA focuses on media files. OP provides rich information about the originator, that’s different. And it’s different from the X.509 based trust list system. Refer to the architecture document for more details.

We want feedback. We’ll open source the docs and code. We’re working on a contributor agreement. We expect this to happen in a few weeks. We’ll open source the code before TPAC 2025.

We have major newspaper and broadcaster companies on board. We welcome your questions.

Tzviya: There are some questions in [GitHub](https://github.com/w3c/authentic-web-workshop/issues/28#issuecomment-3289029940). Jeffrey asked about the threat model, e.g., if an organization misbehaves, what are the consequences?

Shigeya: The charter mentions how to handle rule violations. We don't have a way to handle this in our organization yet. OPCIP profile may be issued only if the organization is committed to the charter. We cannot limit use of OP technology outside the charter, of course, so no way to restrict. Within the OPCIP ecosystem, there’s a commitment to the charter, which sets requirements. The charter says there’ll be a committee to evaluate the situation and determine outcomes. The charter is designed by Japanese lawyers. We might need to make reasonable adjustments for different jurisdictions, but use this as a basis for discussion in the future.

John Fisher: Thanks for the presentation. If some website other than the originator wants to present some content, are they able to do that? Is the verifying key embedded in the content, or how do they get that?

Shigeya: Some news aggregators receive articles from the newspaper companies. Can be posted as in the website, but there’s still some checking policy in the website profile. Needs to be verifiable on a certain domain, for example. Depending on the scenario you want, to use the content from the originator, can implement extensions in the ecosystem. Not sure if this answers the question?

John: Yes, thank you.

Shigeya: Just copying and pasting the attestation is not verifiable.

ChrisN: As a publishing organization — in what formats do we need to provide the content to the aggregator? Typically, we may use a particular XML markup (à la NewsML) to provide the content to an aggregator, which then renders it in HTML using its own formatter. The originator doesn't necessarily have control on the HTML the aggregator might use.

Shigeya: That’s a discussion to have, regarding formats. Within the Japanese ecosystem, some use NewsML, some not. There’s no one format that exists at the moment. So we need to implement multiple schemes, for each distribution format. Needs discussion and research.

Tzviya: Would that be determined on a case by case basis?

Shigeya: Yes, for the Japanese market it’s case by case, as each has its own format. Changing format might be questionable, so needs to be determined case by case. If we can find a better or newer format that people are willing to implement, that would be interesting, but may be far away.

Tzviya: Going back to the [GitHub questions](https://github.com/w3c/authentic-web-workshop/issues/28#issuecomment-3289029940), how might this extend to governments outside Japan? How might that work?

Shigeya: The OP design, the verifier side will decide eventually. Multiple PA providers, and the originator, will provide ??? to verifiers. Information from specific organizations or governments, but how the verifier decides is under their own control. For the media use case, it’s difficult to strictly enforce the verifier behaviour. In certain ecosystems, as example, would content require parental guidance or not? We want to limit it to where there’s parental controls. Limit the use of content in Japan, to prevent malicious sites outside of Japan.

Annette: If you have an originator that abides by the charter, and then there’s a change in government, and the charter agreement isn’t upheld, can you revoke the credential?

Shigeya: I think it’s possible. By using DNSSEC scheme, it’s possible to create a scalable way to revoke the profile annotations.

Annette: Has there been progress to determine how that would actually work?

Shigeya: It’s something we’re thinking about at this stage. Our primary target is media, and news media. We need to think about how the profile annotation can be used in multiple different contexts. One thing I’m trying to do is create a flexible framework that’s useful in multiple contexts and use cases. On example, for the media use case, like newspapers, but beyond that needs discussion.

Tzviya: Jeffrey asked about integrity descriptors or how selectors are used.

Shigeya: I rely on the technical team on those specific questions in GitHub.

Tzviya: One question referred to an article about certificate spoofing and human readable names. How might you avoid a situation like this?

Shigeya: I understand the EV certificate problem. OP requires entity verification to issue the profile. We think that’s not usable enough information about the originator. Any criminal could establish a company and get a certification. We need more info about the origin than that. This is where the policy discussion comes in, e.g., belonging to an organization. An example is the Japanese newspaper association; it proves the organization really is a newspaper organization. This set of validated attributes can help distinguish whether the originator is really the entity that recipients want to communicate with. Membership policy is one example we are thinking about. There’s a way to validate by third parties. For example, bank or security companies can be verified. If you access a site that’s supposed to be a bank or security company, the site can provide validated attributes from this kind of government certified information.

When the user accesses the bank, if it’s certified by a government database, it can show if it's valid or not. Lots of possibilities there.

Dom: My understanding of EV certificates, I think the primary issue is — can any regular end user, who has little time to go into detail, make informed enough decisions? If I go to a website and see a logo that indicates that it’s been validated, but really it’s spoofed, will it really help? The article concludes that relying on the end user to make sense of those verifications may not scale to a wide set of end users.

Tzviya: Didn’t expect you to answer today, worth thinking about

We have a [questionnaire](https://github.com/w3c/authentic-web-workshop/blob/main/AuthenticWebQ.md). This asks about the threat model, but also how the proposal fits with other proposals we’ve heard in the workshop. And what do you expect from W3C?

Shigeya: The architecture overview makes it easier to answer those questions. I’ll fill in the questionnaire soon.

Dom: And role for W3C in helping OP move forward?

Shigeya: One question I have, not in OP, but in Keio: if you read the architecture overview document, it’s abstract and not bound to a specific design. That kind of meta-architecture discussion needs to happen somewhere. W3C is a possible venue, IETF isn’t, possibly IRTF, I want feedback on these venues, to combine that with discussion of implementation experience. Not sure if W3C would welcome this? I’d like to do it at W3C.

Dom: If we had a WG in that space, discussing the architecture before specific technologies would make sense as a first step. We don’t have a WG, but that could be a first validation.

Tzviya: Could have a conversation about how W3C expects specs to evolve, OP has come via quite a different route.

Shigeya: We want to make this available globally. We’re willing to adjust the specification to other needs or potentially coordinate with other entities, if necessary. We’re flexible. We need feedback from attendees in this discussion, for example, to see what’s the best way to do this. We look forward to feedback, in GitHub or email. We want to have a TPAC breakout. In the near term we’ll provide the open source code. We want to listen to your opinions on how to make the technology better, and more useful.

Next meeting in mid-Oct, featuring Dokieli
	